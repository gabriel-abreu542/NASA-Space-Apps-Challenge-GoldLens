#!/usr/bin/env python3
"""
Train a RandomForest classifier across multiple exoplanet missions (KOI, K2, TOI).

This script expects that each mission has been preprocessed by ``ExoPreprocessor``
and saved into a ``processed/`` directory as ``<BASE>_train.csv``,
``<BASE>_valid.csv`` and ``<BASE>_candidates.csv``.  The names ``BASE``
should correspond to the raw CSV filenames without extension (e.g., ``KOIFULL``).

The script performs the following steps:

1. Load the train/valid/candidate splits for all specified bases and
   concatenate them.  Missing features are imputed with the median of
   the combined training set.  A union of columns across bases is
   constructed, and any mission-specific columns that do not appear in a
   particular base will be filled with the global median.

2. Train a RandomForestClassifier using RandomizedSearchCV over a grid
   of hyperparameters with stratified k-fold cross-validation.  The
   training labels only include the binary classes (0 = false positive,
   1 = confirmed planet); candidate objects (label = 2) are excluded
   from the fit.

3. Evaluate the best model on the combined validation set and report
   metrics (accuracy, balanced accuracy, AUC, F1-scores, MCC).
   Additionally, per-mission metrics are printed to help identify
   domainâ€‘shift issues.

4. Rank the candidate objects from all missions by predicted
   probability of being a true planet and print the top 10.

5. Optionally save the trained model to an ``artifacts/`` directory
   with a timestamped filename.

Example usage:

    python train_multi_rf.py --base_names KOIFULL,K2FULL,TOIFULL --save_model

Requirements:
    - pandas
    - numpy
    - scikit-learn
    - joblib
    - processed datasets generated by ExoPreprocessor

Author: ChatGPT (modified for multi-mission training)
"""

from __future__ import annotations

import argparse
from datetime import datetime
from pathlib import Path
import pandas as pd
import numpy as np
import joblib
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV
from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score, f1_score, matthews_corrcoef, confusion_matrix


def compute_metrics(y_true: pd.Series, y_score: np.ndarray, threshold: float = 0.5) -> dict:
    """Compute evaluation metrics given true labels and predicted probabilities."""
    y_pred = (y_score >= threshold).astype(int)
    acc = accuracy_score(y_true, y_pred)
    bal = balanced_accuracy_score(y_true, y_pred)
    try:
        auc = roc_auc_score(y_true, y_score)
    except Exception:
        auc = float("nan")
    f1p = f1_score(y_true, y_pred, pos_label=1)
    f1n = f1_score(y_true, y_pred, pos_label=0)
    mcc = matthews_corrcoef(y_true, y_pred)
    cm = confusion_matrix(y_true, y_pred)
    return {
        "accuracy": acc,
        "balanced_accuracy": bal,
        "auc": auc,
        "f1_positive": f1p,
        "f1_negative": f1n,
        "mcc": mcc,
        "confusion_matrix": cm,
    }


def train_random_forest(
    X_train: pd.DataFrame,
    y_train: pd.Series,
    cv_splits: int = 5,
    n_iter: int = 20,
    random_state: int = 42,
) -> RandomForestClassifier:
    """Train a RandomForestClassifier using RandomizedSearchCV."""
    base_clf = RandomForestClassifier(
        class_weight="balanced",
        random_state=random_state,
        n_jobs=-1,
    )
    param_dist = {
        "n_estimators": [100, 200, 300, 500, 700],
        "max_depth": [10, 15, 20, None],
        "max_features": ["sqrt", 0.5, 0.75],
        "min_samples_split": [2, 5, 10],
        "min_samples_leaf": [1, 2, 4],
    }
    cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=random_state)
    search = RandomizedSearchCV(
        estimator=base_clf,
        param_distributions=param_dist,
        n_iter=n_iter,
        scoring="roc_auc",
        cv=cv,
        random_state=random_state,
        n_jobs=-1,
        verbose=1,
    )
    search.fit(X_train, y_train)
    return search.best_estimator_


def main():
    parser = argparse.ArgumentParser(description="Train a RandomForest across multiple missions and save the model.")
    parser.add_argument(
        "--processed_dir",
        type=str,
        default="processed",
        help="Directory containing processed CSVs (<BASE>_train.csv, etc.).",
    )
    parser.add_argument(
        "--base_names",
        type=str,
        required=True,
        help="Comma-separated list of base names (e.g. KOIFULL,K2FULL,TOIFULL)",
    )
    parser.add_argument(
        "--cv",
        type=int,
        default=5,
        help="Number of folds in cross-validation (default: 5).",
    )
    parser.add_argument(
        "--n_iter",
        type=int,
        default=20,
        help="Number of RandomizedSearchCV iterations (default: 20).",
    )
    parser.add_argument(
        "--threshold",
        type=float,
        default=0.5,
        help="Decision threshold for binary classification (default: 0.5).",
    )
    parser.add_argument(
        "--save_model",
        action="store_true",
        help="If set, save the trained model to an artifacts directory.",
    )
    args = parser.parse_args()

    # Parse bases and ensure directory exists
    bases = [b.strip().upper() for b in args.base_names.split(",") if b.strip()]
    processed_dir = Path(args.processed_dir)
    if not processed_dir.is_dir():
        raise FileNotFoundError(f"Processed directory '{processed_dir}' does not exist.")

    train_dfs: list[pd.DataFrame] = []
    valid_dfs: list[pd.DataFrame] = []
    cand_dfs: list[pd.DataFrame] = []

    # Load train/valid/candidate datasets for each base
    for base in bases:
        train_path = processed_dir / f"{base}_train.csv"
        valid_path = processed_dir / f"{base}_valid.csv"
        cand_path  = processed_dir / f"{base}_candidates.csv"
        if not train_path.exists() or not valid_path.exists() or not cand_path.exists():
            raise FileNotFoundError(f"Missing processed files for base {base} in {processed_dir}")
        train_df = pd.read_csv(train_path)
        valid_df = pd.read_csv(valid_path)
        cand_df  = pd.read_csv(cand_path)
        train_df['mission'] = base  # track mission
        valid_df['mission'] = base
        cand_df['mission'] = base
        train_dfs.append(train_df)
        valid_dfs.append(valid_df)
        cand_dfs.append(cand_df)

    # Combine datasets
    combined_train = pd.concat(train_dfs, axis=0, ignore_index=True, sort=False)
    combined_valid = pd.concat(valid_dfs, axis=0, ignore_index=True, sort=False)
    combined_cand  = pd.concat(cand_dfs, axis=0, ignore_index=True, sort=False)

    # Identify feature columns (exclude 'label' and 'object_id' and 'mission')
    feature_cols = [c for c in combined_train.columns if c not in ("label", "object_id", "mission")]

    # Impute missing with median of training combined
    median_vals = combined_train[feature_cols].median()
    X_train = combined_train[feature_cols].fillna(median_vals)
    y_train = combined_train['label']
    X_valid = combined_valid[feature_cols].fillna(median_vals)
    y_valid = combined_valid['label']

    # Train model
    model = train_random_forest(
        X_train, y_train,
        cv_splits=args.cv,
        n_iter=args.n_iter
    )

    print("\nBest model hyperparameters:")
    print(model.get_params())

    # Evaluate combined validation set
    probs_valid = model.predict_proba(X_valid)[:, 1]
    metrics = compute_metrics(y_valid, probs_valid, threshold=args.threshold)
    print("\nValidation metrics (combined):")
    for k, v in metrics.items():
        if k == "confusion_matrix":
            print(f"  {k}:\n{v}")
        else:
            print(f"  {k}: {v:.4f}")

    # Evaluate per mission
    print("\nValidation metrics by mission:")
    for base in bases:
        mask = combined_valid['mission'] == base
        if mask.any():
            probs_sub = model.predict_proba(X_valid.loc[mask])[:, 1]
            metrics_sub = compute_metrics(y_valid.loc[mask], probs_sub, threshold=args.threshold)
            print(f"Mission {base}:")
            for k, v in metrics_sub.items():
                if k == "confusion_matrix":
                    print(f"  {k}:\n{v}")
                else:
                    print(f"  {k}: {v:.4f}")

    # Feature importance (global)
    importances = model.feature_importances_
    gini_table = sorted(zip(feature_cols, importances), key=lambda x: -x[1])
    print("\nTop 20 features by Gini importance (combined features):")
    for f, imp in gini_table[:20]:
        print(f"  {f:30s} {imp:.6f}")

    # Rank candidate objects across all missions.  Only features present in the
    # training set are used for scoring; mission- or candidate-specific columns
    # not seen during training are ignored.  Missing values are imputed with
    # the combined training medians.
    if not combined_cand.empty:
        # Align candidate features to union of training features
        cand_X = combined_cand.reindex(columns=feature_cols, fill_value=np.nan)
        cand_X = cand_X.fillna(median_vals)
        cand_probs = model.predict_proba(cand_X)[:, 1]
        combined_cand['probability'] = cand_probs
        cand_sorted = combined_cand.sort_values(by='probability', ascending=False)
        print("\nTop 10 candidate objects across all selected bases:")
        # Display object_id and mission if available
        if 'object_id' in combined_cand.columns:
            cols_to_display = ['object_id']
            if 'mission' in combined_cand.columns:
                cols_to_display.append('mission')
            print(cand_sorted[cols_to_display + ['probability']].head(10).to_string(index=False))
        else:
            # If no object_id, just show mission and probability
            cols_to_display = ['mission'] if 'mission' in combined_cand.columns else []
            print(cand_sorted[cols_to_display + ['probability']].head(10).to_string(index=False))

    # Save model if requested
    if args.save_model:
        out_dir = Path('artifacts')
        out_dir.mkdir(exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        model_name = f"rf_{'_'.join(bases)}_{timestamp}.pkl"
        model_path = out_dir / model_name
        joblib.dump(model, model_path)
        print(f"\n[OK] Model saved to: {model_path}")


if __name__ == "__main__":
    main()